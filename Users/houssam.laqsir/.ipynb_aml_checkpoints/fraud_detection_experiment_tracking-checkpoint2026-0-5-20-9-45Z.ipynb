{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dﾃｩtection de Fraude - Experiment Tracking avec Plusieurs Modﾃｨles\n",
        "## Azure ML + MLflow - Comparaison de Versions\n",
        "\n",
        "**Objectif**: Entraﾃｮner et comparer plusieurs versions de modﾃｨles de dﾃｩtection de fraude\n",
        "\n",
        "**Modﾃｨles testﾃｩs**:\n",
        "1. Random Forest (baseline)\n",
        "2. Random Forest (optimisﾃｩ)\n",
        "3. Gradient Boosting\n",
        "4. XGBoost\n",
        "5. LightGBM\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuration et Imports"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn imbalanced-learn matplotlib seaborn mlflow joblib xgboost lightgbm azureml-core\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: pandas in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (2.3.1)\nRequirement already satisfied: numpy in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (2.2.6)\nCollecting scikit-learn\n  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nCollecting imbalanced-learn\n  Downloading imbalanced_learn-0.14.1-py3-none-any.whl.metadata (8.9 kB)\nCollecting matplotlib\n  Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\nCollecting seaborn\n  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting mlflow\n  Downloading mlflow-3.8.1-py3-none-any.whl.metadata (31 kB)\nCollecting joblib\n  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\nCollecting xgboost\n  Downloading xgboost-3.1.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\nCollecting lightgbm\n  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\nRequirement already satisfied: azureml-core in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (1.60.0.post1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pandas) (2025.2)\nRequirement already satisfied: scipy>=1.8.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn)\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\nCollecting sklearn-compat<0.2,>=0.1.5 (from imbalanced-learn)\n  Downloading sklearn_compat-0.1.5-py3-none-any.whl.metadata (20 kB)\nCollecting contourpy>=1.0.1 (from matplotlib)\n  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nCollecting cycler>=0.10 (from matplotlib)\n  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting fonttools>=4.22.0 (from matplotlib)\n  Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\nCollecting kiwisolver>=1.3.1 (from matplotlib)\n  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (25.0)\nCollecting pillow>=8 (from matplotlib)\n  Downloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\nCollecting pyparsing>=3 (from matplotlib)\n  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting mlflow-skinny==3.8.1 (from mlflow)\n  Downloading mlflow_skinny-3.8.1-py3-none-any.whl.metadata (31 kB)\nCollecting mlflow-tracing==3.8.1 (from mlflow)\n  Downloading mlflow_tracing-3.8.1-py3-none-any.whl.metadata (19 kB)\nCollecting Flask-CORS<7 (from mlflow)\n  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\nCollecting Flask<4 (from mlflow)\n  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting alembic!=1.10.0,<2 (from mlflow)\n  Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: cryptography<47,>=43.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (45.0.5)\nRequirement already satisfied: docker<8,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting huey<3,>=2.5.0 (from mlflow)\n  Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\nRequirement already satisfied: pyarrow<23,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (20.0.0)\nCollecting sqlalchemy<3,>=1.4.0 (from mlflow)\n  Downloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (8.2.1)\nRequirement already satisfied: cloudpickle<4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.8.1->mlflow)\n  Downloading databricks_sdk-0.76.0-py3-none-any.whl.metadata (40 kB)\nCollecting fastapi<1 (from mlflow-skinny==3.8.1->mlflow)\n  Downloading fastapi-0.128.0-py3-none-any.whl.metadata (30 kB)\nCollecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.8.1->mlflow)\n  Downloading gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.35.0)\nRequirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.35.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.35.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (6.31.1)\nRequirement already satisfied: pydantic<3,>=2.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (2.11.7)\nCollecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.8.1->mlflow)\n  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: pyyaml<7,>=5.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (2.32.4)\nCollecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.8.1->mlflow)\n  Downloading sqlparse-0.5.5-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (4.14.1)\nCollecting uvicorn<1 (from mlflow-skinny==3.8.1->mlflow)\n  Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\nCollecting Mako (from alembic!=1.10.0,<2->mlflow)\n  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: tomli in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (2.2.1)\nRequirement already satisfied: cffi>=1.14 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from cryptography<47,>=43.0.0->mlflow) (1.15.0)\nRequirement already satisfied: google-auth~=2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (2.40.3)\nRequirement already satisfied: urllib3>=1.26.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\nCollecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.8.1->mlflow)\n  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\nCollecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.8.1->mlflow)\n  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\nCollecting blinker>=1.9.0 (from Flask<4->mlflow)\n  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting itsdangerous>=2.2.0 (from Flask<4->mlflow)\n  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: jinja2>=3.1.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from Flask<4->mlflow) (2.1.1)\nRequirement already satisfied: werkzeug>=3.1.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.3)\nCollecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow)\n  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\nCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow)\n  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (4.9.1)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: zipp>=3.20 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.8.1->mlflow) (3.23.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow) (0.56b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (0.4.1)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (2025.7.9)\nRequirement already satisfied: pyasn1>=0.1.3 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (0.6.1)\nCollecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow)\n  Downloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: anyio<5,>=3.6.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow) (3.7.1)\nRequirement already satisfied: sniffio>=1.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow) (1.3.1)\nRequirement already satisfied: exceptiongroup in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow) (1.3.0)\nRequirement already satisfied: h11>=0.8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from uvicorn<1->mlflow-skinny==3.8.1->mlflow) (0.16.0)\nCollecting nvidia-nccl-cu12 (from xgboost)\n  Downloading nvidia_nccl_cu12-2.28.9-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\nRequirement already satisfied: backports.tempfile in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.0)\nRequirement already satisfied: pathspec<1.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.12.1)\nRequirement already satisfied: msal<2.0.0,>=1.15.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.32.3)\nRequirement already satisfied: msal-extensions<=2.0.0,>=0.3.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.3.1)\nRequirement already satisfied: knack<0.13.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.12.0)\nRequirement already satisfied: azure-core<2.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.35.0)\nRequirement already satisfied: pkginfo in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.12.1.2)\nRequirement already satisfied: argcomplete<4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (3.6.2)\nRequirement already satisfied: humanfriendly<11.0,>=4.7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (10.0)\nRequirement already satisfied: paramiko<4.0.0,>=2.0.8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (3.5.1)\nRequirement already satisfied: azure-mgmt-resource<=24.0.0,>=15.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (24.0.0)\nRequirement already satisfied: azure-mgmt-containerregistry<14,>=8.2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (13.0.0)\nRequirement already satisfied: azure-mgmt-storage<=23.0.0,>=16.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (23.0.0)\nRequirement already satisfied: azure-mgmt-keyvault<12.0.0,>=0.40.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (11.0.0)\nRequirement already satisfied: azure-mgmt-authorization<5,>=0.40.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (4.0.0)\nRequirement already satisfied: azure-mgmt-network<=29.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (29.0.0)\nRequirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.61.2)\nRequirement already satisfied: azure-common<2.0.0,>=1.1.12 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.1.28)\nRequirement already satisfied: msrest<=0.7.1,>=0.5.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.7.1)\nRequirement already satisfied: msrestazure<=0.7,>=0.4.33 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.6.4.post1)\nRequirement already satisfied: ndg-httpsclient<=0.5.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.5.1)\nRequirement already satisfied: SecretStorage<4.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (3.3.3)\nRequirement already satisfied: jsonpickle<5.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (4.1.1)\nRequirement already satisfied: contextlib2<22.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (21.6.0)\nRequirement already satisfied: PyJWT<3.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (2.10.1)\nRequirement already satisfied: adal<=1.2.7,>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.2.7)\nRequirement already satisfied: pyopenssl<26.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (25.1.0)\nRequirement already satisfied: jmespath<2.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.0.1)\nRequirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core) (0.7.2)\nRequirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core) (1.6.0)\nRequirement already satisfied: pygments in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from knack<0.13.0->azureml-core) (2.19.2)\nRequirement already satisfied: tabulate in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from knack<0.13.0->azureml-core) (0.9.0)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core) (2.0.0)\nRequirement already satisfied: bcrypt>=3.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core) (4.3.0)\nRequirement already satisfied: pynacl>=1.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core) (1.5.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (1.7.1)\nRequirement already satisfied: jeepney>=0.6 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from SecretStorage<4.0.0->azureml-core) (0.9.0)\nRequirement already satisfied: pycparser in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from cffi>=1.14->cryptography<47,>=43.0.0->mlflow) (2.22)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core) (3.3.1)\nRequirement already satisfied: backports.weakref in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from backports.tempfile->azureml-core) (1.0.post1)\nDownloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading imbalanced_learn-0.14.1-py3-none-any.whl (235 kB)\nDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\nDownloading sklearn_compat-0.1.5-py3-none-any.whl (20 kB)\nDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nDownloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\nDownloading mlflow-3.8.1-py3-none-any.whl (9.1 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-3.8.1-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mlflow_tracing-3.8.1-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading alembic-1.17.2-py3-none-any.whl (248 kB)\nDownloading databricks_sdk-0.76.0-py3-none-any.whl (774 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m774.7/774.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.128.0-py3-none-any.whl (103 kB)\nDownloading flask-3.1.2-py3-none-any.whl (103 kB)\nDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\nDownloading gitpython-3.1.46-py3-none-any.whl (208 kB)\nDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\nDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\nDownloading huey-2.5.5-py3-none-any.whl (76 kB)\nDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\nDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\nDownloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m129.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sqlparse-0.5.5-py3-none-any.whl (46 kB)\nDownloading starlette-0.50.0-py3-none-any.whl (74 kB)\nDownloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\nDownloading xgboost-3.1.2-py3-none-manylinux_2_28_x86_64.whl (115.9 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m115.9/115.9 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\nDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\nDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\nDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\nDownloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (586 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nDownloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\nDownloading mako-1.3.10-py3-none-any.whl (78 kB)\nDownloading nvidia_nccl_cu12-2.28.9-py3-none-manylinux_2_18_x86_64.whl (296.8 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m296.8/296.8 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huey, uvicorn, threadpoolctl, sqlparse, smmap, python-dotenv, pyparsing, pillow, nvidia-nccl-cu12, Mako, kiwisolver, joblib, itsdangerous, gunicorn, greenlet, graphql-core, fonttools, cycler, contourpy, blinker, annotated-doc, xgboost, sqlalchemy, scikit-learn, matplotlib, lightgbm, graphql-relay, gitdb, Flask, starlette, sklearn-compat, seaborn, graphene, gitpython, Flask-CORS, databricks-sdk, alembic, imbalanced-learn, fastapi, mlflow-tracing, mlflow-skinny, mlflow\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m42/42\u001b[0m [mlflow] [mlflow] [mlflow-skinny]]n]\n\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.2 Mako-1.3.10 alembic-1.17.2 annotated-doc-0.0.4 blinker-1.9.0 contourpy-1.3.2 cycler-0.12.1 databricks-sdk-0.76.0 fastapi-0.128.0 fonttools-4.61.1 gitdb-4.0.12 gitpython-3.1.46 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.3.0 gunicorn-23.0.0 huey-2.5.5 imbalanced-learn-0.14.1 itsdangerous-2.2.0 joblib-1.5.3 kiwisolver-1.4.9 lightgbm-4.6.0 matplotlib-3.10.8 mlflow-3.8.1 mlflow-skinny-3.8.1 mlflow-tracing-3.8.1 nvidia-nccl-cu12-2.28.9 pillow-12.1.0 pyparsing-3.3.1 python-dotenv-1.2.1 scikit-learn-1.7.2 seaborn-0.13.2 sklearn-compat-0.1.5 smmap-5.0.2 sqlalchemy-2.0.45 sqlparse-0.5.5 starlette-0.50.0 threadpoolctl-3.6.0 uvicorn-0.40.0 xgboost-3.1.2\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1767643584020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Azure ML\n",
        "from azureml.core import Workspace, Experiment, Run\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, \n",
        "    roc_auc_score, roc_curve, precision_recall_curve,\n",
        "    f1_score, precision_score, recall_score, accuracy_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Algorithmes avancﾃｩs\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# MLflow\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.xgboost\n",
        "import mlflow.lightgbm\n",
        "\n",
        "import joblib\n",
        "\n",
        "print(\"笨 Bibliothﾃｨques importﾃｩes avec succﾃｨs\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "笨 Bibliothﾃｨques importﾃｩes avec succﾃｨs\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1767643601462
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Connexion Azure ML"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Connexion au workspace\n",
        "try:\n",
        "    ws = Workspace.from_config()\n",
        "    print(f\"笨 Connectﾃｩ au workspace: {ws.name}\")\n",
        "except:\n",
        "    ws = Workspace(\n",
        "        subscription_id='<VOTRE_SUBSCRIPTION_ID>',\n",
        "        resource_group='<VOTRE_RESOURCE_GROUP>',\n",
        "        workspace_name='<VOTRE_WORKSPACE_NAME>'\n",
        "    )\n",
        "    print(f\"笨 Connectﾃｩ au workspace: {ws.name}\")\n",
        "\n",
        "# Crﾃｩer l'expﾃｩrience principale\n",
        "experiment_name = 'fraud-detection-model-comparison'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "print(f\"笨 Expﾃｩrience crﾃｩﾃｩe: {experiment_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "笨 Connectﾃｩ au workspace: creditfraudml\n笨 Expﾃｩrience crﾃｩﾃｩe: fraud-detection-model-comparison\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1767643622428
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Chargement et Prﾃｩparation des Donnﾃｩes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azureml-dataset-runtime --upgrade"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting azureml-dataset-runtime\n  Downloading azureml_dataset_runtime-1.61.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting azureml-dataprep<5.5.0a,>=5.1.0a (from azureml-dataset-runtime)\n  Downloading azureml_dataprep-5.4.2-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: pyarrow<21.0.0,>=0.17.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-dataset-runtime) (20.0.0)\nRequirement already satisfied: numpy!=1.19.3,<2.3.3 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-dataset-runtime) (2.2.6)\nCollecting azureml-dataprep-native<43.0.0,>=42.0.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime)\n  Downloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting azureml-dataprep-rslex~=2.25.1 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime)\n  Downloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting cloudpickle<3.0.0,>=1.1.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime)\n  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\nCollecting azure-identity<=1.17.0,>=1.16.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime)\n  Downloading azure_identity-1.17.0-py3-none-any.whl.metadata (79 kB)\nRequirement already satisfied: jsonschema in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (4.24.0)\nRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (6.0.2)\nCollecting pip>=25.3 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime)\n  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (1.35.0)\nRequirement already satisfied: cryptography>=2.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (45.0.5)\nRequirement already satisfied: msal>=1.24.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (1.32.3)\nRequirement already satisfied: msal-extensions>=0.3.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (1.3.1)\nRequirement already satisfied: typing-extensions>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (4.14.1)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (2.32.4)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (1.17.0)\nRequirement already satisfied: cffi>=1.14 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (1.15.0)\nRequirement already satisfied: pycparser in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (2.22)\nRequirement already satisfied: PyJWT<3,>=1.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.24.0->azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (2.10.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-identity<=1.17.0,>=1.16.0->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (2025.7.9)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime) (0.22.3)\nDownloading azureml_dataset_runtime-1.61.0-py3-none-any.whl (2.3 kB)\nDownloading azureml_dataprep-5.4.2-py3-none-any.whl (253 kB)\nDownloading azure_identity-1.17.0-py3-none-any.whl (173 kB)\nDownloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl (187 kB)\nDownloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl (26.1 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\nDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: azureml-dataprep-rslex, pip, cloudpickle, azureml-dataprep-native, azure-identity, azureml-dataprep, azureml-dataset-runtime\n\u001b[2K  Attempting uninstall: pip笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m0/7\u001b[0m [azureml-dataprep-rslex]\n\u001b[2K    Found existing installation: pip 25.1笏≫煤笏―u001b[0m \u001b[32m0/7\u001b[0m [azureml-dataprep-rslex]\n\u001b[2K    Uninstalling pip-25.1:m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1/7\u001b[0m [pip]\n\u001b[2K      Successfully uninstalled pip-25.1笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m1/7\u001b[0m [pip]\n\u001b[2K  Attempting uninstall: cloudpickle笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m1/7\u001b[0m [pip]\n\u001b[2K    Found existing installation: cloudpickle 3.1.1笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1/7\u001b[0m [pip]\n\u001b[2K    Uninstalling cloudpickle-3.1.1:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m1/7\u001b[0m [pip]\n\u001b[2K      Successfully uninstalled cloudpickle-3.1.1笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1/7\u001b[0m [pip]\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m7/7\u001b[0m [azureml-dataset-runtime]l-dataprep]\n\u001b[1A\u001b[2KSuccessfully installed azure-identity-1.17.0 azureml-dataprep-5.4.2 azureml-dataprep-native-42.1.0 azureml-dataprep-rslex-2.25.2 azureml-dataset-runtime-1.61.0 cloudpickle-2.2.1 pip-25.3\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1767643778826
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger les donnﾃｩes\n",
        "from azureml.core import Workspace, Dataset, Datastore\n",
        "\n",
        "datastore = Datastore.get(ws, datastore_name='workspaceblobstore')\n",
        "\n",
        "dataset = Dataset.Tabular.from_delimited_files(\n",
        "    path=[(datastore, 'fraud_dataset.csv')]\n",
        ")\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "print(f\"笨 Donnﾃｩes chargﾃｩes: {df.shape[0]:,} lignes, {df.shape[1]} colonnes\")\n",
        "print(f\"\\n沒 Distribution des classes:\")\n",
        "print(df['isFraud'].value_counts())\n",
        "print(f\"\\nTaux de fraude: {df['isFraud'].mean()*100:.4f}%\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Missing required package \"azureml-dataset-runtime\", which can be installed by running: \"/anaconda/envs/jupyter_env/bin/python\" -m pip install azureml-dataset-runtime --upgrade",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mazureml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workspace, Dataset, Datastore\n\u001b[1;32m      4\u001b[0m datastore \u001b[38;5;241m=\u001b[39m Datastore\u001b[38;5;241m.\u001b[39mget(ws, datastore_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworkspaceblobstore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTabular\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_delimited_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatastore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfraud_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mto_pandas_dataframe()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m笨 Donnﾃｩes chargﾃｩes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lignes, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m colonnes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/jupyter_env/lib/python3.10/site-packages/azureml/data/_loggerfactory.py:140\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _LoggerFactory\u001b[38;5;241m.\u001b[39mtrack_activity(logger, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions) \u001b[38;5;28;01mas\u001b[39;00m al:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(al, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_info\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
            "File \u001b[0;32m/anaconda/envs/jupyter_env/lib/python3.10/site-packages/azureml/data/dataset_factory.py:340\u001b[0m, in \u001b[0;36mTabularDatasetFactory.from_delimited_files\u001b[0;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format, support_multi_line, empty_as_string, encoding)\u001b[0m\n\u001b[1;32m    338\u001b[0m path \u001b[38;5;241m=\u001b[39m _validate_and_normalize_path(path)\n\u001b[1;32m    339\u001b[0m _trace_dataset_creation(path)\n\u001b[0;32m--> 340\u001b[0m dataflow \u001b[38;5;241m=\u001b[39m \u001b[43mdataprep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(path,\n\u001b[1;32m    341\u001b[0m                                verify_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    342\u001b[0m                                include_path\u001b[38;5;241m=\u001b[39minclude_path,\n\u001b[1;32m    343\u001b[0m                                infer_column_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    344\u001b[0m                                separator\u001b[38;5;241m=\u001b[39mseparator,\n\u001b[1;32m    345\u001b[0m                                header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    346\u001b[0m                                quoting\u001b[38;5;241m=\u001b[39msupport_multi_line,\n\u001b[1;32m    347\u001b[0m                                empty_as_string\u001b[38;5;241m=\u001b[39mempty_as_string,\n\u001b[1;32m    348\u001b[0m                                encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m    350\u001b[0m dataflow \u001b[38;5;241m=\u001b[39m _transform_and_validate(\n\u001b[1;32m    351\u001b[0m     dataflow\u001b[38;5;241m=\u001b[39mdataflow,\n\u001b[1;32m    352\u001b[0m     partition_format\u001b[38;5;241m=\u001b[39mpartition_format,\n\u001b[1;32m    353\u001b[0m     validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    354\u001b[0m     infer_column_types\u001b[38;5;241m=\u001b[39minfer_column_types \u001b[38;5;129;01mor\u001b[39;00m _is_inference_required(set_column_types, validate))\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infer_column_types:\n",
            "File \u001b[0;32m/anaconda/envs/jupyter_env/lib/python3.10/site-packages/azureml/data/_dataprep_helper.py:36\u001b[0m, in \u001b[0;36mdataprep\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdataprep\u001b[39m():\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dataprep_installed():\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(get_dataprep_missing_message())\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mazureml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataprep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_dprep\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     check_min_version()\n",
            "\u001b[0;31mImportError\u001b[0m: Missing required package \"azureml-dataset-runtime\", which can be installed by running: \"/anaconda/envs/jupyter_env/bin/python\" -m pip install azureml-dataset-runtime --upgrade"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1767643696036
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "print(\"沐ｧ Feature Engineering en cours...\")\n",
        "\n",
        "# Encoder le type de transaction\n",
        "df = pd.get_dummies(df, columns=['type'], prefix='type', drop_first=False)\n",
        "\n",
        "# Features dﾃｩrivﾃｩes\n",
        "df['balanceChange_orig'] = df['oldbalanceOrg'] - df['newbalanceOrig']\n",
        "df['balanceChange_dest'] = df['newbalanceDest'] - df['oldbalanceDest']\n",
        "df['amountToBalanceRatio_orig'] = df['amount'] / (df['oldbalanceOrg'] + 1)\n",
        "df['isOriginEmpty'] = (df['newbalanceOrig'] == 0).astype(int)\n",
        "df['isDestEmpty'] = (df['oldbalanceDest'] == 0).astype(int)\n",
        "df['errorBalanceOrig'] = df['balanceChange_orig'] - df['amount']\n",
        "df['errorBalanceDest'] = df['balanceChange_dest'] - df['amount']\n",
        "\n",
        "# Supprimer colonnes non nﾃｩcessaires\n",
        "df = df.drop(columns=['nameOrig', 'nameDest', 'isFlaggedFraud'], errors='ignore')\n",
        "\n",
        "print(f\"笨 Feature Engineering complﾃｩtﾃｩ - {df.shape[1]} features\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Sﾃｩparation X/y\n",
        "X = df.drop('isFraud', axis=1)\n",
        "y = df['isFraud']\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Train/Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]:,} transactions\")\n",
        "print(f\"Test set: {X_test.shape[0]:,} transactions\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisation\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"笨 Donnﾃｩes normalisﾃｩes\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Balancing\n",
        "print(\"笞厄ｸ Rﾃｩﾃｩquilibrage des donnﾃｩes...\")\n",
        "\n",
        "over = SMOTE(sampling_strategy=0.5, random_state=42)\n",
        "under = RandomUnderSampler(sampling_strategy=0.8, random_state=42)\n",
        "\n",
        "X_train_balanced, y_train_balanced = over.fit_resample(X_train_scaled, y_train)\n",
        "X_train_balanced, y_train_balanced = under.fit_resample(X_train_balanced, y_train_balanced)\n",
        "\n",
        "print(f\"笨 Donnﾃｩes rﾃｩﾃｩquilibrﾃｩes: {len(y_train_balanced):,} transactions\")\n",
        "print(f\"Distribution: {pd.Series(y_train_balanced).value_counts().to_dict()}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Fonction Utilitaire pour l'Experiment Tracking"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(model, model_name, X_train, y_train, X_test, y_test, run):\n",
        "    \"\"\"\n",
        "    Entraﾃｮne un modﾃｨle et log toutes les mﾃｩtriques dans Azure ML\n",
        "    \n",
        "    Args:\n",
        "        model: Le modﾃｨle ﾃ entraﾃｮner\n",
        "        model_name: Nom du modﾃｨle pour le tracking\n",
        "        X_train, y_train: Donnﾃｩes d'entraﾃｮnement\n",
        "        X_test, y_test: Donnﾃｩes de test\n",
        "        run: Azure ML Run object\n",
        "    \n",
        "    Returns:\n",
        "        dict: Mﾃｩtriques de performance\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"泅 Entraﾃｮnement: {model_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # Entraﾃｮnement\n",
        "    start_time = datetime.now()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = (datetime.now() - start_time).total_seconds()\n",
        "    \n",
        "    # Prﾃｩdictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Calcul des mﾃｩtriques\n",
        "    metrics = {\n",
        "        'model_name': model_name,\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred),\n",
        "        'recall': recall_score(y_test, y_pred),\n",
        "        'f1_score': f1_score(y_test, y_pred),\n",
        "        'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
        "        'training_time_seconds': training_time\n",
        "    }\n",
        "    \n",
        "    # Log des mﾃｩtriques dans Azure ML\n",
        "    run.log('model_name', model_name)\n",
        "    run.log('accuracy', metrics['accuracy'])\n",
        "    run.log('precision', metrics['precision'])\n",
        "    run.log('recall', metrics['recall'])\n",
        "    run.log('f1_score', metrics['f1_score'])\n",
        "    run.log('roc_auc', metrics['roc_auc'])\n",
        "    run.log('training_time_seconds', training_time)\n",
        "    \n",
        "    # Affichage des rﾃｩsultats\n",
        "    print(f\"\\n沒 Rﾃｩsultats:\")\n",
        "    print(f\"  Accuracy:  {metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
        "    print(f\"  F1-Score:  {metrics['f1_score']:.4f}\")\n",
        "    print(f\"  ROC-AUC:   {metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Temps:     {training_time:.2f}s\")\n",
        "    \n",
        "    # Matrice de confusion\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Lﾃｩgal', 'Fraude'],\n",
        "                yticklabels=['Lﾃｩgal', 'Fraude'])\n",
        "    plt.title(f'Matrice de Confusion - {model_name}', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Vraie Classe')\n",
        "    plt.xlabel('Classe Prﾃｩdite')\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Sauvegarder et logger l'image\n",
        "    img_path = f'confusion_matrix_{model_name.replace(\" \", \"_\")}.png'\n",
        "    plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
        "    run.log_image(f'confusion_matrix_{model_name}', plot=plt)\n",
        "    plt.close()\n",
        "    \n",
        "    return metrics, model, y_pred_proba\n",
        "\n",
        "print(\"笨 Fonction d'ﾃｩvaluation crﾃｩﾃｩe\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Experiment Tracking - Entraﾃｮnement de Plusieurs Modﾃｨles\n",
        "\n",
        "Nous allons entraﾃｮner et comparer 5 versions diffﾃｩrentes de modﾃｨles"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Dﾃｩmarrer le run parent\n",
        "parent_run = experiment.start_logging()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"洫ｪ Dﾃ隠UT DE L'EXPERIMENT TRACKING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Expﾃｩrience: {experiment.name}\")\n",
        "print(f\"Run ID: {parent_run.id}\")\n",
        "\n",
        "# Dictionnaire pour stocker tous les rﾃｩsultats\n",
        "all_results = []\n",
        "all_models = {}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modﾃｨle 1: Random Forest (Baseline)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Child run 1\n",
        "child_run_1 = parent_run.child_run(name=\"RF_Baseline\")\n",
        "\n",
        "model_1 = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "# Log des hyperparamﾃｨtres\n",
        "child_run_1.log('n_estimators', 50)\n",
        "child_run_1.log('max_depth', 10)\n",
        "child_run_1.log('algorithm', 'RandomForest')\n",
        "\n",
        "metrics_1, trained_model_1, proba_1 = train_and_evaluate_model(\n",
        "    model_1, 'Random Forest (Baseline)', \n",
        "    X_train_balanced, y_train_balanced, \n",
        "    X_test_scaled, y_test,\n",
        "    child_run_1\n",
        ")\n",
        "\n",
        "all_results.append(metrics_1)\n",
        "all_models['RF_Baseline'] = trained_model_1\n",
        "child_run_1.complete()\n",
        "print(\"笨 Modﾃｨle 1 complﾃｩtﾃｩ\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modﾃｨle 2: Random Forest (Optimisﾃｩ)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Child run 2\n",
        "child_run_2 = parent_run.child_run(name=\"RF_Optimized\")\n",
        "\n",
        "model_2 = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "child_run_2.log('n_estimators', 100)\n",
        "child_run_2.log('max_depth', 20)\n",
        "child_run_2.log('min_samples_split', 10)\n",
        "child_run_2.log('min_samples_leaf', 5)\n",
        "child_run_2.log('algorithm', 'RandomForest')\n",
        "\n",
        "metrics_2, trained_model_2, proba_2 = train_and_evaluate_model(\n",
        "    model_2, 'Random Forest (Optimisﾃｩ)', \n",
        "    X_train_balanced, y_train_balanced, \n",
        "    X_test_scaled, y_test,\n",
        "    child_run_2\n",
        ")\n",
        "\n",
        "all_results.append(metrics_2)\n",
        "all_models['RF_Optimized'] = trained_model_2\n",
        "child_run_2.complete()\n",
        "print(\"笨 Modﾃｨle 2 complﾃｩtﾃｩ\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modﾃｨle 3: Gradient Boosting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Child run 3\n",
        "child_run_3 = parent_run.child_run(name=\"GradientBoosting\")\n",
        "\n",
        "model_3 = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "child_run_3.log('n_estimators', 100)\n",
        "child_run_3.log('learning_rate', 0.1)\n",
        "child_run_3.log('max_depth', 5)\n",
        "child_run_3.log('algorithm', 'GradientBoosting')\n",
        "\n",
        "metrics_3, trained_model_3, proba_3 = train_and_evaluate_model(\n",
        "    model_3, 'Gradient Boosting', \n",
        "    X_train_balanced, y_train_balanced, \n",
        "    X_test_scaled, y_test,\n",
        "    child_run_3\n",
        ")\n",
        "\n",
        "all_results.append(metrics_3)\n",
        "all_models['GradientBoosting'] = trained_model_3\n",
        "child_run_3.complete()\n",
        "print(\"笨 Modﾃｨle 3 complﾃｩtﾃｩ\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modﾃｨle 4: XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Child run 4\n",
        "child_run_4 = parent_run.child_run(name=\"XGBoost\")\n",
        "\n",
        "# Calculer le scale_pos_weight pour gﾃｩrer le dﾃｩsﾃｩquilibre\n",
        "scale_pos_weight = (y_train_balanced == 0).sum() / (y_train_balanced == 1).sum()\n",
        "\n",
        "model_4 = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "child_run_4.log('n_estimators', 100)\n",
        "child_run_4.log('max_depth', 6)\n",
        "child_run_4.log('learning_rate', 0.1)\n",
        "child_run_4.log('scale_pos_weight', scale_pos_weight)\n",
        "child_run_4.log('algorithm', 'XGBoost')\n",
        "\n",
        "metrics_4, trained_model_4, proba_4 = train_and_evaluate_model(\n",
        "    model_4, 'XGBoost', \n",
        "    X_train_balanced, y_train_balanced, \n",
        "    X_test_scaled, y_test,\n",
        "    child_run_4\n",
        ")\n",
        "\n",
        "all_results.append(metrics_4)\n",
        "all_models['XGBoost'] = trained_model_4\n",
        "child_run_4.complete()\n",
        "print(\"笨 Modﾃｨle 4 complﾃｩtﾃｩ\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modﾃｨle 5: LightGBM"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Child run 5\n",
        "child_run_5 = parent_run.child_run(name=\"LightGBM\")\n",
        "\n",
        "model_5 = lgb.LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=31,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "child_run_5.log('n_estimators', 100)\n",
        "child_run_5.log('max_depth', 6)\n",
        "child_run_5.log('learning_rate', 0.1)\n",
        "child_run_5.log('num_leaves', 31)\n",
        "child_run_5.log('algorithm', 'LightGBM')\n",
        "\n",
        "metrics_5, trained_model_5, proba_5 = train_and_evaluate_model(\n",
        "    model_5, 'LightGBM', \n",
        "    X_train_balanced, y_train_balanced, \n",
        "    X_test_scaled, y_test,\n",
        "    child_run_5\n",
        ")\n",
        "\n",
        "all_results.append(metrics_5)\n",
        "all_models['LightGBM'] = trained_model_5\n",
        "child_run_5.complete()\n",
        "print(\"笨 Modﾃｨle 5 complﾃｩtﾃｩ\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Comparaison des Rﾃｩsultats de Tous les Modﾃｨles"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Crﾃｩer un DataFrame de comparaison\n",
        "comparison_df = pd.DataFrame(all_results)\n",
        "comparison_df = comparison_df.sort_values('f1_score', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"沒 TABLEAU COMPARATIF DES MODﾃLES\")\n",
        "print(\"=\"*100)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*100)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarder le tableau de comparaison\n",
        "comparison_df.to_csv('model_comparison.csv', index=False)\n",
        "parent_run.upload_file('model_comparison.csv', 'model_comparison.csv')\n",
        "print(\"笨 Tableau de comparaison sauvegardﾃｩ\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation comparative - Graphique en barres\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Comparaison des Performances des Modﾃｨles', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc', 'training_time_seconds']\n",
        "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'Temps (s)']\n",
        "\n",
        "for idx, (metric, name) in enumerate(zip(metrics_to_plot, metric_names)):\n",
        "    row = idx // 3\n",
        "    col = idx % 3\n",
        "    ax = axes[row, col]\n",
        "    \n",
        "    # Extraire les valeurs\n",
        "    models = comparison_df['model_name'].values\n",
        "    values = comparison_df[metric].values\n",
        "    \n",
        "    # Crﾃｩer le graphique\n",
        "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(models)))\n",
        "    bars = ax.bar(range(len(models)), values, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    \n",
        "    # Ajouter les valeurs sur les barres\n",
        "    for i, (bar, val) in enumerate(zip(bars, values)):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.4f}' if metric != 'training_time_seconds' else f'{val:.2f}',\n",
        "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "    \n",
        "    ax.set_xticks(range(len(models)))\n",
        "    ax.set_xticklabels(models, rotation=45, ha='right', fontsize=9)\n",
        "    ax.set_ylabel(name, fontsize=11, fontweight='bold')\n",
        "    ax.set_title(name, fontsize=12, fontweight='bold')\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison_bars.png', dpi=300, bbox_inches='tight')\n",
        "parent_run.log_image('model_comparison_bars', plot=plt)\n",
        "plt.show()\n",
        "\n",
        "print(\"笨 Graphiques de comparaison crﾃｩﾃｩs\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Radar Chart pour visualisation multi-dimensionnelle\n",
        "from math import pi\n",
        "\n",
        "# Prﾃｩparer les donnﾃｩes pour le radar chart\n",
        "categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
        "N = len(categories)\n",
        "\n",
        "# Crﾃｩer les angles pour chaque axe\n",
        "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "angles += angles[:1]\n",
        "\n",
        "# Initialiser le plot\n",
        "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "# Tracer chaque modﾃｨle\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
        "for idx, row in comparison_df.iterrows():\n",
        "    values = [\n",
        "        row['accuracy'],\n",
        "        row['precision'],\n",
        "        row['recall'],\n",
        "        row['f1_score'],\n",
        "        row['roc_auc']\n",
        "    ]\n",
        "    values += values[:1]\n",
        "    \n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=row['model_name'], color=colors[idx % len(colors)])\n",
        "    ax.fill(angles, values, alpha=0.15, color=colors[idx % len(colors)])\n",
        "\n",
        "# Configurer le graphique\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(categories, size=11)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_title('Comparaison Multi-Dimensionnelle des Modﾃｨles', size=16, fontweight='bold', pad=20)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)\n",
        "ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison_radar.png', dpi=300, bbox_inches='tight')\n",
        "parent_run.log_image('model_comparison_radar', plot=plt)\n",
        "plt.show()\n",
        "\n",
        "print(\"笨 Radar chart crﾃｩﾃｩ\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Sﾃｩlection et Enregistrement du Meilleur Modﾃｨle"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifier le meilleur modﾃｨle basﾃｩ sur le F1-Score\n",
        "best_model_row = comparison_df.iloc[0]\n",
        "best_model_name = best_model_row['model_name']\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"沛 MEILLEUR MODﾃLE Sﾃ鵜ECTIONNﾃ噂")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nModﾃｨle: {best_model_name}\")\n",
        "print(f\"\\nPerformances:\")\n",
        "print(f\"  - Accuracy:  {best_model_row['accuracy']:.4f}\")\n",
        "print(f\"  - Precision: {best_model_row['precision']:.4f}\")\n",
        "print(f\"  - Recall:    {best_model_row['recall']:.4f}\")\n",
        "print(f\"  - F1-Score:  {best_model_row['f1_score']:.4f}\")\n",
        "print(f\"  - ROC-AUC:   {best_model_row['roc_auc']:.4f}\")\n",
        "print(\"=\"*70)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Rﾃｩcupﾃｩrer le meilleur modﾃｨle\n",
        "model_key = best_model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "if 'Baseline' in best_model_name:\n",
        "    best_model = all_models['RF_Baseline']\n",
        "elif 'Optimisﾃｩ' in best_model_name:\n",
        "    best_model = all_models['RF_Optimized']\n",
        "elif 'Gradient' in best_model_name:\n",
        "    best_model = all_models['GradientBoosting']\n",
        "elif 'XGBoost' in best_model_name:\n",
        "    best_model = all_models['XGBoost']\n",
        "elif 'LightGBM' in best_model_name:\n",
        "    best_model = all_models['LightGBM']\n",
        "\n",
        "# Sauvegarder le meilleur modﾃｨle\n",
        "best_model_filename = 'best_fraud_detection_model.pkl'\n",
        "joblib.dump(best_model, best_model_filename)\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "print(f\"笨 Meilleur modﾃｨle sauvegardﾃｩ: {best_model_filename}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Enregistrer dans Azure ML\n",
        "parent_run.upload_file(name='outputs/' + best_model_filename, path_or_stream=best_model_filename)\n",
        "parent_run.upload_file(name='outputs/scaler.pkl', path_or_stream='scaler.pkl')\n",
        "\n",
        "# Enregistrer comme modﾃｨle Azure ML\n",
        "registered_model = parent_run.register_model(\n",
        "    model_name='fraud-detection-best',\n",
        "    model_path='outputs/' + best_model_filename,\n",
        "    description=f'Best fraud detection model: {best_model_name}',\n",
        "    tags={\n",
        "        'algorithm': best_model_name,\n",
        "        'accuracy': f\"{best_model_row['accuracy']:.4f}\",\n",
        "        'f1_score': f\"{best_model_row['f1_score']:.4f}\",\n",
        "        'roc_auc': f\"{best_model_row['roc_auc']:.4f}\",\n",
        "        'experiment': experiment_name\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"笨 Modﾃｨle enregistrﾃｩ dans Azure ML: {registered_model.name}, Version: {registered_model.version}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Enregistrer tous les modﾃｨles individuellement\n",
        "print(\"\\n沒ｦ Enregistrement de tous les modﾃｨles...\")\n",
        "\n",
        "for idx, row in comparison_df.iterrows():\n",
        "    model_name = row['model_name']\n",
        "    model_key = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "    \n",
        "    if 'Baseline' in model_name:\n",
        "        model = all_models['RF_Baseline']\n",
        "    elif 'Optimisﾃｩ' in model_name:\n",
        "        model = all_models['RF_Optimized']\n",
        "    elif 'Gradient' in model_name:\n",
        "        model = all_models['GradientBoosting']\n",
        "    elif 'XGBoost' in model_name:\n",
        "        model = all_models['XGBoost']\n",
        "    elif 'LightGBM' in model_name:\n",
        "        model = all_models['LightGBM']\n",
        "    \n",
        "    filename = f\"model_{model_key}.pkl\"\n",
        "    joblib.dump(model, filename)\n",
        "    print(f\"  笨 {model_name} sauvegardﾃｩ\")\n",
        "\n",
        "print(\"\\n笨 Tous les modﾃｨles ont ﾃｩtﾃｩ enregistrﾃｩs\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Terminer le run parent\n",
        "parent_run.complete()\n",
        "print(\"\\n笨 Expﾃｩrience Azure ML terminﾃｩe\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Export pour Power BI"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Export du tableau de comparaison pour Power BI\n",
        "comparison_df.to_csv('model_comparison_powerbi.csv', index=False)\n",
        "\n",
        "# Crﾃｩer un rﾃｩsumﾃｩ dﾃｩtaillﾃｩ\n",
        "summary_df = comparison_df.copy()\n",
        "summary_df['rank'] = range(1, len(summary_df) + 1)\n",
        "summary_df = summary_df[[\n",
        "    'rank', 'model_name', 'accuracy', 'precision', 'recall', \n",
        "    'f1_score', 'roc_auc', 'training_time_seconds'\n",
        "]]\n",
        "\n",
        "summary_df.to_csv('models_detailed_summary.csv', index=False)\n",
        "\n",
        "print(\"笨 Fichiers exportﾃｩs pour Power BI:\")\n",
        "print(\"   - model_comparison_powerbi.csv\")\n",
        "print(\"   - models_detailed_summary.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Rﾃｩcapitulatif Final"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "笊披武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶風\n",
        "笊              Rﾃ韻APITULATIF DE L'EXPERIMENT TRACKING                笊曾n",
        "笊壺武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶幅\n",
        "\n",
        "笨 MODﾃLES ENTRAﾃ晒ﾃ唄 ET COMPARﾃ唄:\n",
        "   1. Random Forest (Baseline) - Configuration simple\n",
        "   2. Random Forest (Optimisﾃｩ) - Hyperparamﾃｨtres tunﾃｩs\n",
        "   3. Gradient Boosting - Approche boosting traditionnelle\n",
        "   4. XGBoost - Extreme Gradient Boosting\n",
        "   5. LightGBM - Light Gradient Boosting Machine\n",
        "\n",
        "沒 Mﾃ欝RIQUES TRACKﾃ右S:\n",
        "   窶｢ Accuracy\n",
        "   窶｢ Precision\n",
        "   窶｢ Recall\n",
        "   窶｢ F1-Score\n",
        "   窶｢ ROC-AUC\n",
        "   窶｢ Temps d'entraﾃｮnement\n",
        "\n",
        "沐 EXPERIMENT TRACKING:\n",
        "   窶｢ Toutes les expﾃｩriences loggﾃｩes dans Azure ML\n",
        "   窶｢ Mﾃｩtriques comparables dans le portail Azure\n",
        "   窶｢ Visualisations automatiquement gﾃｩnﾃｩrﾃｩes\n",
        "   窶｢ Modﾃｨles versionnﾃｩs et sauvegardﾃｩs\n",
        "\n",
        "沒 VISUALISATIONS CRﾃ嘉右S:\n",
        "   窶｢ Matrices de confusion pour chaque modﾃｨle\n",
        "   窶｢ Graphiques en barres comparatifs\n",
        "   窶｢ Radar chart multi-dimensionnel\n",
        "\n",
        "汳ｾ FICHIERS Gﾃ丑ﾃ嘘ﾃ唄:\n",
        "   窶｢ model_comparison.csv - Tableau comparatif complet\n",
        "   窶｢ best_fraud_detection_model.pkl - Meilleur modﾃｨle\n",
        "   窶｢ model_*.pkl - Tous les modﾃｨles individuels\n",
        "   窶｢ scaler.pkl - Normalisation des donnﾃｩes\n",
        "   窶｢ *_powerbi.csv - Fichiers pour Power BI\n",
        "\n",
        "笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武\n",
        "\"\"\")\n",
        "\n",
        "print(f\"\\n沛 MEILLEUR MODﾃLE: {best_model_name}\")\n",
        "print(f\"   F1-Score: {best_model_row['f1_score']:.4f}\")\n",
        "print(f\"   ROC-AUC: {best_model_row['roc_auc']:.4f}\")\n",
        "print(f\"\\n竢ｰ Date de fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"\\n沁 EXPERIMENT TRACKING COMPLﾃ欝ﾃ AVEC SUCCﾃS! 沁噂\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}