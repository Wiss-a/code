{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# D√©tection de Fraude dans les Transactions Financi√®res\n",
        "## Azure Machine Learning + Power BI\n",
        "\n",
        "**Objectif**: Entra√Æner un mod√®le de for√™ts al√©atoires pour d√©tecter les transactions frauduleuses et pr√©parer les visualisations pour Power BI.\n",
        "\n",
        "**Dataset**: 6M de transactions avec ~8k cas de fraude (classe tr√®s d√©s√©quilibr√©e)\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuration et Installation des D√©pendances"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation des packages n√©cessaires\n",
        "!pip install azureml-sdk pandas numpy scikit-learn imbalanced-learn matplotlib seaborn mlflow joblib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azureml-sdk in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.60.0)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.23.5)\nRequirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.7.2)\nRequirement already satisfied: imbalanced-learn in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.12.4)\nRequirement already satisfied: matplotlib in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (3.7.1)\nRequirement already satisfied: seaborn in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: mlflow in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (3.2.0)\nRequirement already satisfied: joblib in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.2.0)\nRequirement already satisfied: azureml-core~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-sdk) (1.60.0)\nRequirement already satisfied: azureml-dataset-runtime~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (1.60.0)\nRequirement already satisfied: azureml-train-core~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-sdk) (1.60.0)\nRequirement already satisfied: azureml-train-automl-client~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-sdk) (1.60.0)\nRequirement already satisfied: azureml-pipeline~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-sdk) (1.60.0)\nRequirement already satisfied: pytz in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (2022.5)\nRequirement already satisfied: backports.tempfile in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (1.0)\nRequirement already satisfied: pathspec<1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (0.12.1)\nRequirement already satisfied: requests<3.0.0,>=2.19.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.60.0->azureml-sdk) (2.32.3)\nRequirement already satisfied: msal<2.0.0,>=1.15.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (1.33.0b1)\nRequirement already satisfied: msal-extensions<=2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (1.2.0)\nRequirement already satisfied: knack<0.13.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (0.11.0)\nRequirement already satisfied: azure-core<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (1.33.0)\nRequirement already satisfied: pkginfo in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (1.12.1.2)\nRequirement already satisfied: argcomplete<4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (3.5.3)\nRequirement already satisfied: humanfriendly<11.0,>=4.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (10.0)\nRequirement already satisfied: paramiko<4.0.0,>=2.0.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (3.5.1)\nRequirement already satisfied: azure-mgmt-resource<=24.0.0,>=15.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (23.3.0)\nRequirement already satisfied: azure-mgmt-containerregistry<11,>=8.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (9.0.0)\nRequirement already satisfied: azure-mgmt-storage<=23.0.0,>=16.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (22.0.0)\nRequirement already satisfied: azure-mgmt-keyvault<11.0.0,>=0.40.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (10.3.1)\nRequirement already satisfied: azure-mgmt-authorization<5,>=0.40.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (4.0.0)\nRequirement already satisfied: azure-mgmt-network<=29.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (26.0.0)\nRequirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (0.60.0)\nRequirement already satisfied: azure-common<2.0.0,>=1.1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (1.1.28)\nRequirement already satisfied: msrest<=0.7.1,>=0.5.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (0.7.1)\nRequirement already satisfied: msrestazure<=0.7,>=0.4.33 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (0.6.4.post1)\nRequirement already satisfied: urllib3<3.0.0,>1.26.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (1.26.20)\nRequirement already satisfied: packaging<=25.0,>=20.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (25.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (2.9.0.post0)\nRequirement already satisfied: ndg-httpsclient<=0.5.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (0.5.1)\nRequirement already satisfied: SecretStorage<4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (3.3.3)\nRequirement already satisfied: jsonpickle<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (4.0.5)\nRequirement already satisfied: contextlib2<22.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (21.6.0)\nRequirement already satisfied: docker<8.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (7.1.0)\nRequirement already satisfied: PyJWT<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (2.4.0)\nRequirement already satisfied: adal<=1.2.7,>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (1.2.7)\nRequirement already satisfied: pyopenssl<26.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (23.0.0)\nRequirement already satisfied: jmespath<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core~=1.60.0->azureml-sdk) (0.10.0)\nRequirement already satisfied: cryptography>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from adal<=1.2.7,>=1.2.0->azureml-core~=1.60.0->azureml-sdk) (38.0.4)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core<2.0.0->azureml-core~=1.60.0->azureml-sdk) (1.17.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core<2.0.0->azureml-core~=1.60.0->azureml-sdk) (4.13.2)\nRequirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.60.0->azureml-sdk) (0.7.2)\nRequirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.60.0->azureml-sdk) (1.5.0)\nRequirement already satisfied: azureml-dataprep<5.2.0a,>=5.1.0a in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (5.1.6)\nRequirement already satisfied: pyarrow>=0.17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (14.0.2)\nRequirement already satisfied: azureml-dataprep-native<42.0.0,>=41.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (41.0.0)\nRequirement already satisfied: azureml-dataprep-rslex~=2.22.2dev0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (2.22.5)\nRequirement already satisfied: cloudpickle<3.0.0,>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (2.2.1)\nRequirement already satisfied: azure-identity>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (1.21.0)\nRequirement already satisfied: jsonschema in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (4.23.0)\nRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (6.0.2)\nRequirement already satisfied: fusepy<4.0.0,>=3.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (3.0.1)\nRequirement already satisfied: azureml-pipeline-core~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-pipeline~=1.60.0->azureml-sdk) (1.60.0)\nRequirement already satisfied: azureml-pipeline-steps~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-pipeline~=1.60.0->azureml-sdk) (1.60.0)\nRequirement already satisfied: azureml-automl-core~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-train-automl-client~=1.60.0->azureml-sdk) (1.60.0)\nRequirement already satisfied: azureml-telemetry~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-train-automl-client~=1.60.0->azureml-sdk) (1.60.0)\nRequirement already satisfied: importlib-metadata<=8.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-automl-core~=1.60.0->azureml-train-automl-client~=1.60.0->azureml-sdk) (8.2.0)\nRequirement already satisfied: importlib-resources<=6.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-automl-core~=1.60.0->azureml-train-automl-client~=1.60.0->azureml-sdk) (6.4.0)\nRequirement already satisfied: applicationinsights in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-telemetry~=1.60.0->azureml-train-automl-client~=1.60.0->azureml-sdk) (0.11.10)\nRequirement already satisfied: azureml-train-restclients-hyperdrive~=1.60.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-train-core~=1.60.0->azureml-sdk) (1.60.0)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from importlib-metadata<=8.2.0->azureml-automl-core~=1.60.0->azureml-train-automl-client~=1.60.0->azureml-sdk) (3.12.0)\nRequirement already satisfied: pygments in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from knack<0.13.0->azureml-core~=1.60.0->azureml-sdk) (2.19.1)\nRequirement already satisfied: tabulate in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from knack<0.13.0->azureml-core~=1.60.0->azureml-sdk) (0.9.0)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.60.0->azureml-sdk) (1.17.1)\nRequirement already satisfied: portalocker<3,>=1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msal-extensions<=2.0.0,>=0.3.0->azureml-core~=1.60.0->azureml-sdk) (2.10.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.60.0->azureml-sdk) (2025.7.9)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.60.0->azureml-sdk) (2.0.0)\nRequirement already satisfied: pyasn1>=0.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ndg-httpsclient<=0.5.1->azureml-core~=1.60.0->azureml-sdk) (0.6.1)\nRequirement already satisfied: bcrypt>=3.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.60.0->azureml-sdk) (4.3.0)\nRequirement already satisfied: pynacl>=1.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.60.0->azureml-sdk) (1.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.19.1->requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.60.0->azureml-sdk) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.19.1->requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.60.0->azureml-sdk) (3.10)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.60.0->azureml-sdk) (1.7.1)\nRequirement already satisfied: jeepney>=0.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from SecretStorage<4.0.0->azureml-core~=1.60.0->azureml-sdk) (0.9.0)\nRequirement already satisfied: scipy>=1.8.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (1.11.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (9.2.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (3.2.3)\nRequirement already satisfied: mlflow-skinny==3.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow) (3.2.0)\nRequirement already satisfied: mlflow-tracing==3.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow) (3.2.0)\nRequirement already satisfied: Flask<4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow) (3.0.3)\nRequirement already satisfied: alembic!=1.10.0,<2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow) (1.17.2)\nRequirement already satisfied: graphene<4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow) (23.0.0)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow) (2.0.45)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (8.1.8)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (0.49.0)\nRequirement already satisfied: fastapi<1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (0.115.12)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (3.1.44)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (1.35.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (1.35.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (4.25.8)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (2.9.2)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (0.5.3)\nRequirement already satisfied: uvicorn<1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from mlflow-skinny==3.2.0->mlflow) (0.34.0)\nRequirement already satisfied: Mako in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: tomli in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (2.2.1)\nRequirement already satisfied: google-auth~=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (2.38.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from fastapi<1->mlflow-skinny==3.2.0->mlflow) (0.46.1)\nRequirement already satisfied: Werkzeug>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: itsdangerous>=2.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from Flask<4->mlflow) (2.1.2)\nRequirement already satisfied: blinker>=1.6.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.2.0->mlflow) (4.0.12)\nRequirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.2.0->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (4.9)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.7)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.2.0->mlflow) (0.56b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.2.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.2.0->mlflow) (2.23.4)\nRequirement already satisfied: greenlet>=1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\nRequirement already satisfied: anyio<5,>=3.6.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.2.0->mlflow) (4.9.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.2.0->mlflow) (1.2.2)\nRequirement already satisfied: sniffio>=1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.2.0->mlflow) (1.3.1)\nRequirement already satisfied: h11>=0.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from uvicorn<1->mlflow-skinny==3.2.0->mlflow) (0.14.0)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.60.0->azureml-sdk) (2.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask<4->mlflow) (3.0.3)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.60.0->azureml-sdk) (3.2.2)\nRequirement already satisfied: backports.weakref in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from backports.tempfile->azureml-core~=1.60.0->azureml-sdk) (1.0.post1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.60.0->azureml-dataset-runtime[fuse]~=1.60.0->azureml-sdk) (0.19.1)\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1767562077633
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Azure ML\n",
        "from azureml.core import Workspace, Dataset, Experiment, Run\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report, \n",
        "    confusion_matrix, \n",
        "    roc_auc_score, \n",
        "    roc_curve,\n",
        "    precision_recall_curve,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# MLflow pour le suivi d'exp√©rience\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# Joblib pour la s√©rialisation\n",
        "import joblib\n",
        "\n",
        "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Connexion √† Azure ML Workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Connexion au workspace Azure ML\n",
        "# Option 1: Depuis un fichier config.json\n",
        "try:\n",
        "    ws = Workspace.from_config()\n",
        "    print(f\"‚úÖ Connect√© au workspace: {ws.name}\")\n",
        "except:\n",
        "    # Option 2: Connexion manuelle\n",
        "    ws = Workspace(\n",
        "        subscription_id='<VOTRE_SUBSCRIPTION_ID>',\n",
        "        resource_group='<VOTRE_RESOURCE_GROUP>',\n",
        "        workspace_name='<VOTRE_WORKSPACE_NAME>'\n",
        "    )\n",
        "    print(f\"‚úÖ Connect√© au workspace: {ws.name}\")\n",
        "\n",
        "# Cr√©er une exp√©rience\n",
        "experiment_name = 'fraud-detection-experiment'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "print(f\"‚úÖ Exp√©rience cr√©√©e: {experiment_name}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Ingestion - Chargement des Donn√©es"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Charger depuis Azure Blob Storage ou Dataset enregistr√©\n",
        "# dataset = Dataset.get_by_name(ws, name='fraud_transactions')\n",
        "# df = dataset.to_pandas_dataframe()\n",
        "\n",
        "# Option 2: Charger depuis un fichier local ou un chemin\n",
        "# Remplacez par le chemin de votre dataset\n",
        "df = pd.read_csv('fraud_transactions.csv')\n",
        "\n",
        "print(f\"‚úÖ Donn√©es charg√©es: {df.shape[0]:,} lignes, {df.shape[1]} colonnes\")\n",
        "print(f\"\\nüìä Distribution des classes:\")\n",
        "print(df['is_fraud'].value_counts())\n",
        "print(f\"\\nTaux de fraude: {df['is_fraud'].mean()*100:.4f}%\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Aper√ßu des donn√©es\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Informations sur le dataset\n",
        "df.info()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Analyse Exploratoire des Donn√©es (EDA)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistiques descriptives\n",
        "df.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation de la distribution des classes\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Graphique en barres\n",
        "df['is_fraud'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
        "axes[0].set_title('Distribution des Classes', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Classe (0=L√©gal, 1=Fraude)')\n",
        "axes[0].set_ylabel('Nombre de transactions')\n",
        "axes[0].set_xticklabels(['L√©gal', 'Fraude'], rotation=0)\n",
        "\n",
        "# Graphique en camembert\n",
        "colors = ['#2ecc71', '#e74c3c']\n",
        "df['is_fraud'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.2f%%', colors=colors)\n",
        "axes[1].set_title('Proportion Fraude vs L√©gal', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"D√©s√©quilibre des classes: {df['is_fraud'].value_counts()[0] / df['is_fraud'].value_counts()[1]:.1f}:1\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice de corr√©lation (pour les features num√©riques)\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "correlation_matrix = df[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Matrice de Corr√©lation des Features', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Pr√©paration des Donn√©es (Data Processing)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Gestion des valeurs manquantes\n",
        "print(\"Valeurs manquantes par colonne:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Remplir ou supprimer les valeurs manquantes selon le besoin\n",
        "# Exemple: df.fillna(df.median(), inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Donn√©es apr√®s nettoyage: {df.shape[0]:,} lignes\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering (Exemples - √† adapter selon vos colonnes)\n",
        "# Supposons que vous avez des colonnes comme: amount, time, category, etc.\n",
        "\n",
        "# Exemple: Cr√©er des features temporelles si vous avez une colonne 'timestamp'\n",
        "if 'timestamp' in df.columns:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
        "\n",
        "# Exemple: Encodage des variables cat√©gorielles\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "if len(categorical_cols) > 0:\n",
        "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"‚úÖ Feature Engineering compl√©t√©\")\n",
        "print(f\"Nombre total de features: {df.shape[1]}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# S√©paration des features et de la target\n",
        "# Ajustez 'is_fraud' selon le nom de votre colonne cible\n",
        "X = df.drop('is_fraud', axis=1)\n",
        "y = df['is_fraud']\n",
        "\n",
        "# Sauvegarder les noms des colonnes pour plus tard\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "print(f\"\\nDistribution de y:\\n{y.value_counts()}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Split Train/Test"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Division train/test (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=y  # Maintenir la proportion des classes\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]:,} transactions\")\n",
        "print(f\"Test set: {X_test.shape[0]:,} transactions\")\n",
        "print(f\"\\nDistribution train:\")\n",
        "print(y_train.value_counts())\n",
        "print(f\"\\nDistribution test:\")\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Normalisation des Donn√©es"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardisation des features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Donn√©es normalis√©es\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Data Balancing - Gestion du D√©s√©quilibre des Classes\n",
        "\n",
        "Avec un ratio de ~750:1 (6M l√©gitimes vs 8K fraudes), nous utilisons une approche hybride:\n",
        "- **SMOTE** pour augmenter les cas de fraude\n",
        "- **RandomUnderSampler** pour r√©duire les cas l√©gitimes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Strat√©gie de r√©√©quilibrage hybride\n",
        "# SMOTE pour oversampling de la classe minoritaire\n",
        "# Puis undersampling de la classe majoritaire\n",
        "\n",
        "# Calculer les ratios souhait√©s\n",
        "fraud_count = y_train.sum()\n",
        "legit_count = len(y_train) - fraud_count\n",
        "\n",
        "print(f\"Avant r√©√©quilibrage:\")\n",
        "print(f\"  - Transactions l√©gitimes: {legit_count:,}\")\n",
        "print(f\"  - Transactions frauduleuses: {fraud_count:,}\")\n",
        "print(f\"  - Ratio: {legit_count/fraud_count:.1f}:1\")\n",
        "\n",
        "# Pipeline de r√©√©quilibrage\n",
        "# D'abord SMOTE pour cr√©er des exemples synth√©tiques de fraude\n",
        "# Puis undersampling pour r√©duire les transactions l√©gitimes\n",
        "sampling_strategy_smote = 0.5  # Augmenter les fraudes √† 50% des l√©gitimes\n",
        "sampling_strategy_under = 0.8  # R√©duire pour avoir un ratio de 1:1.25\n",
        "\n",
        "over = SMOTE(sampling_strategy=sampling_strategy_smote, random_state=42)\n",
        "under = RandomUnderSampler(sampling_strategy=sampling_strategy_under, random_state=42)\n",
        "\n",
        "# Appliquer le pipeline\n",
        "X_train_balanced, y_train_balanced = over.fit_resample(X_train_scaled, y_train)\n",
        "X_train_balanced, y_train_balanced = under.fit_resample(X_train_balanced, y_train_balanced)\n",
        "\n",
        "print(f\"\\nApr√®s r√©√©quilibrage:\")\n",
        "print(f\"  - Total: {len(y_train_balanced):,} transactions\")\n",
        "print(f\"  - Distribution:\")\n",
        "print(pd.Series(y_train_balanced).value_counts())\n",
        "print(f\"  - Nouveau ratio: {pd.Series(y_train_balanced).value_counts()[0] / pd.Series(y_train_balanced).value_counts()[1]:.2f}:1\")\n",
        "print(\"\\n‚úÖ Donn√©es r√©√©quilibr√©es avec succ√®s\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Model Training - Entra√Ænement du Mod√®le Random Forest"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# D√©marrer le run MLflow\n",
        "run = experiment.start_logging()\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "print(\"üöÄ D√©marrage de l'entra√Ænement du mod√®le Random Forest...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Configuration du mod√®le Random Forest\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,          # Nombre d'arbres\n",
        "    max_depth=20,              # Profondeur maximale\n",
        "    min_samples_split=10,      # Minimum d'√©chantillons pour split\n",
        "    min_samples_leaf=5,        # Minimum d'√©chantillons par feuille\n",
        "    max_features='sqrt',       # Nombre de features √† consid√©rer\n",
        "    random_state=42,\n",
        "    n_jobs=-1,                 # Utiliser tous les CPU\n",
        "    verbose=1,\n",
        "    class_weight='balanced'    # Poids automatique des classes\n",
        ")\n",
        "\n",
        "# Entra√Ænement\n",
        "start_time = datetime.now()\n",
        "rf_model.fit(X_train_balanced, y_train_balanced)\n",
        "training_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "print(f\"\\n‚úÖ Entra√Ænement termin√© en {training_time:.2f} secondes\")\n",
        "\n",
        "# Log des hyperparam√®tres\n",
        "run.log('n_estimators', 100)\n",
        "run.log('max_depth', 20)\n",
        "run.log('training_time_seconds', training_time)\n",
        "run.log('training_samples', len(y_train_balanced))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. √âvaluation du Mod√®le"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Pr√©dictions sur le test set\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "y_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# M√©triques de performance\n",
        "accuracy = rf_model.score(X_test_scaled, y_test)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä R√âSULTATS DU MOD√àLE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Log des m√©triques dans Azure ML\n",
        "run.log('accuracy', accuracy)\n",
        "run.log('precision', precision)\n",
        "run.log('recall', recall)\n",
        "run.log('f1_score', f1)\n",
        "run.log('roc_auc', roc_auc)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Rapport de classification d√©taill√©\n",
        "print(\"\\nüìã Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['L√©gal', 'Fraude']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice de confusion\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['L√©gal', 'Fraude'], \n",
        "            yticklabels=['L√©gal', 'Fraude'])\n",
        "plt.title('Matrice de Confusion', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Vraie Classe')\n",
        "plt.xlabel('Classe Pr√©dite')\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "run.log_image('confusion_matrix', plot=plt)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nVrais N√©gatifs (TN): {cm[0, 0]:,}\")\n",
        "print(f\"Faux Positifs (FP): {cm[0, 1]:,}\")\n",
        "print(f\"Faux N√©gatifs (FN): {cm[1, 0]:,}\")\n",
        "print(f\"Vrais Positifs (TP): {cm[1, 1]:,}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Courbe ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taux de Faux Positifs (FPR)', fontsize=12)\n",
        "plt.ylabel('Taux de Vrais Positifs (TPR)', fontsize=12)\n",
        "plt.title('Courbe ROC - D√©tection de Fraude', fontsize=16, fontweight='bold')\n",
        "plt.legend(loc=\"lower right\", fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "run.log_image('roc_curve', plot=plt)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Courbe Precision-Recall\n",
        "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(recall_curve, precision_curve, color='blue', lw=2)\n",
        "plt.xlabel('Recall', fontsize=12)\n",
        "plt.ylabel('Precision', fontsize=12)\n",
        "plt.title('Courbe Precision-Recall', fontsize=16, fontweight='bold')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
        "run.log_image('precision_recall_curve', plot=plt)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Feature Importance - Importance des Variables"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraire l'importance des features\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# Top 20 features les plus importantes\n",
        "top_n = 20\n",
        "top_features = feature_importance.head(top_n)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
        "plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "plt.xlabel('Importance', fontsize=12)\n",
        "plt.title(f'Top {top_n} Features les Plus Importantes', fontsize=16, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "run.log_image('feature_importance', plot=plt)\n",
        "plt.show()\n",
        "\n",
        "# Afficher le dataframe\n",
        "print(\"\\nüìä Top 10 Features:\")\n",
        "print(feature_importance.head(10))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Sauvegarde du Mod√®le"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarder le mod√®le et le scaler localement\n",
        "model_filename = 'fraud_detection_rf_model.pkl'\n",
        "scaler_filename = 'scaler.pkl'\n",
        "\n",
        "joblib.dump(rf_model, model_filename)\n",
        "joblib.dump(scaler, scaler_filename)\n",
        "\n",
        "print(f\"‚úÖ Mod√®le sauvegard√©: {model_filename}\")\n",
        "print(f\"‚úÖ Scaler sauvegard√©: {scaler_filename}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Enregistrer le mod√®le dans Azure ML\n",
        "run.upload_file(name='outputs/' + model_filename, path_or_stream=model_filename)\n",
        "run.upload_file(name='outputs/' + scaler_filename, path_or_stream=scaler_filename)\n",
        "\n",
        "# Enregistrer comme mod√®le Azure ML\n",
        "model = run.register_model(\n",
        "    model_name='fraud-detection-rf',\n",
        "    model_path='outputs/' + model_filename,\n",
        "    description='Random Forest model for fraud detection',\n",
        "    tags={\n",
        "        'algorithm': 'RandomForest',\n",
        "        'framework': 'scikit-learn',\n",
        "        'accuracy': f'{accuracy:.4f}',\n",
        "        'f1_score': f'{f1:.4f}',\n",
        "        'roc_auc': f'{roc_auc:.4f}'\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Mod√®le enregistr√© dans Azure ML: {model.name}, Version: {model.version}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Terminer le run\n",
        "run.complete()\n",
        "print(\"‚úÖ Exp√©rience Azure ML termin√©e\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Pr√©paration des Donn√©es pour Power BI"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Cr√©er un DataFrame avec les pr√©dictions pour Power BI\n",
        "results_df = X_test.copy()\n",
        "results_df['actual_fraud'] = y_test.values\n",
        "results_df['predicted_fraud'] = y_pred\n",
        "results_df['fraud_probability'] = y_pred_proba\n",
        "\n",
        "# Cat√©goriser les pr√©dictions\n",
        "results_df['prediction_category'] = results_df['fraud_probability'].apply(\n",
        "    lambda x: 'Haute Suspicion' if x >= 0.8 else \n",
        "              ('Suspicion Moyenne' if x >= 0.5 else 'Faible Suspicion')\n",
        ")\n",
        "\n",
        "# Identifier les erreurs du mod√®le\n",
        "results_df['prediction_result'] = 'Correct'\n",
        "results_df.loc[(results_df['actual_fraud'] == 1) & (results_df['predicted_fraud'] == 0), 'prediction_result'] = 'Faux N√©gatif'\n",
        "results_df.loc[(results_df['actual_fraud'] == 0) & (results_df['predicted_fraud'] == 1), 'prediction_result'] = 'Faux Positif'\n",
        "\n",
        "print(f\"‚úÖ DataFrame de r√©sultats cr√©√©: {results_df.shape}\")\n",
        "results_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Cr√©er un r√©sum√© des m√©triques pour Power BI\n",
        "metrics_summary = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
        "    'Value': [accuracy, precision, recall, f1, roc_auc]\n",
        "})\n",
        "\n",
        "print(\"\\nüìä R√©sum√© des M√©triques:\")\n",
        "print(metrics_summary)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Cr√©er des statistiques par cat√©gorie de pr√©diction\n",
        "category_stats = results_df.groupby('prediction_category').agg({\n",
        "    'fraud_probability': ['count', 'mean', 'min', 'max'],\n",
        "    'actual_fraud': 'sum'\n",
        "}).round(4)\n",
        "category_stats.columns = ['Count', 'Avg_Probability', 'Min_Probability', 'Max_Probability', 'Actual_Frauds']\n",
        "category_stats = category_stats.reset_index()\n",
        "\n",
        "print(\"\\nüìä Statistiques par Cat√©gorie:\")\n",
        "print(category_stats)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse des transactions suspectes (probabilit√© > 0.8)\n",
        "suspicious_transactions = results_df[results_df['fraud_probability'] > 0.8].copy()\n",
        "suspicious_transactions = suspicious_transactions.sort_values('fraud_probability', ascending=False)\n",
        "\n",
        "print(f\"\\nüö® Transactions Hautement Suspectes: {len(suspicious_transactions):,}\")\n",
        "print(f\"   - Vraies fraudes d√©tect√©es: {suspicious_transactions['actual_fraud'].sum():,}\")\n",
        "print(f\"   - Taux de pr√©cision: {suspicious_transactions['actual_fraud'].mean()*100:.2f}%\")\n",
        "\n",
        "suspicious_transactions.head(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14. Export des Donn√©es pour Power BI"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Export vers CSV pour Power BI\n",
        "results_df.to_csv('fraud_predictions_powerbi.csv', index=False)\n",
        "metrics_summary.to_csv('model_metrics_powerbi.csv', index=False)\n",
        "category_stats.to_csv('category_statistics_powerbi.csv', index=False)\n",
        "suspicious_transactions.to_csv('suspicious_transactions_powerbi.csv', index=False)\n",
        "feature_importance.to_csv('feature_importance_powerbi.csv', index=False)\n",
        "\n",
        "print(\"‚úÖ Fichiers export√©s pour Power BI:\")\n",
        "print(\"   - fraud_predictions_powerbi.csv\")\n",
        "print(\"   - model_metrics_powerbi.csv\")\n",
        "print(\"   - category_statistics_powerbi.csv\")\n",
        "print(\"   - suspicious_transactions_powerbi.csv\")\n",
        "print(\"   - feature_importance_powerbi.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15. Guide d'Int√©gration Power BI"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë           GUIDE D'INT√âGRATION POWER BI                             ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "üìä FICHIERS EXPORT√âS POUR POWER BI:\n",
        "   ‚úì fraud_predictions_powerbi.csv - Toutes les pr√©dictions\n",
        "   ‚úì model_metrics_powerbi.csv - M√©triques du mod√®le\n",
        "   ‚úì category_statistics_powerbi.csv - Stats par cat√©gorie\n",
        "   ‚úì suspicious_transactions_powerbi.csv - Transactions suspectes\n",
        "   ‚úì feature_importance_powerbi.csv - Importance des variables\n",
        "\n",
        "üéØ VISUALISATIONS RECOMMAND√âES DANS POWER BI:\n",
        "\n",
        "1. DASHBOARD PRINCIPAL:\n",
        "   ‚Ä¢ Carte de KPI: Nombre total de fraudes d√©tect√©es\n",
        "   ‚Ä¢ Carte de KPI: Taux de pr√©cision du mod√®le\n",
        "   ‚Ä¢ Carte de KPI: F1-Score\n",
        "   ‚Ä¢ Graphique en anneau: R√©partition L√©gitimes vs Fraudes\n",
        "\n",
        "2. ANALYSE DES TRANSACTIONS SUSPECTES:\n",
        "   ‚Ä¢ Tableau: Top 100 transactions les plus suspectes\n",
        "   ‚Ä¢ Graphique en barres: Nombre de transactions par cat√©gorie de suspicion\n",
        "   ‚Ä¢ Graphique lin√©aire: √âvolution temporelle des fraudes (si date disponible)\n",
        "\n",
        "3. PERFORMANCE DU MOD√àLE:\n",
        "   ‚Ä¢ Matrice de confusion (visuel personnalis√©)\n",
        "   ‚Ä¢ Graphique en colonnes: M√©triques du mod√®le\n",
        "   ‚Ä¢ Courbe ROC (si possible avec visuel personnalis√©)\n",
        "\n",
        "4. ANALYSE DES FEATURES:\n",
        "   ‚Ä¢ Graphique en barres horizontales: Top 20 features importantes\n",
        "   ‚Ä¢ Graphique de dispersion: Relation entre features et fraude\n",
        "\n",
        "5. FILTRES INTERACTIFS:\n",
        "   ‚Ä¢ Filtre par cat√©gorie de pr√©diction\n",
        "   ‚Ä¢ Filtre par r√©sultat de pr√©diction (Correct, FP, FN)\n",
        "   ‚Ä¢ Filtre par probabilit√© de fraude (seuils ajustables)\n",
        "\n",
        "üí° √âTAPES D'IMPORT DANS POWER BI:\n",
        "   1. Ouvrir Power BI Desktop\n",
        "   2. Obtenir des donn√©es > Fichier CSV\n",
        "   3. S√©lectionner les fichiers CSV export√©s\n",
        "   4. Transformer les donn√©es si n√©cessaire (Power Query)\n",
        "   5. Cr√©er les relations entre les tables\n",
        "   6. Construire vos visualisations\n",
        "   7. Publier vers Power BI Service pour partage\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\"\"\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 16. R√©sum√© Final"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë                    R√âSUM√â DU PROJET                                ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "‚úÖ √âTAPES COMPL√âT√âES:\n",
        "   1. ‚úì Data Ingestion - Chargement de 6M de transactions\n",
        "   2. ‚úì Data Processing - Nettoyage et feature engineering\n",
        "   3. ‚úì Data Balancing - R√©√©quilibrage SMOTE + UnderSampling\n",
        "   4. ‚úì Model Training - Random Forest avec 100 arbres\n",
        "   5. ‚úì Experiment Tracking - Enregistrement dans Azure ML\n",
        "   6. ‚úì Model Evaluation - M√©triques et visualisations\n",
        "   7. ‚úì Model Deployment - Sauvegarde et enregistrement Azure\n",
        "   8. ‚úì Power BI Export - Fichiers CSV pr√™ts pour l'import\n",
        "\n",
        "üéâ PROJET COMPL√âT√â AVEC SUCC√àS! üéâ\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\"\"\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}